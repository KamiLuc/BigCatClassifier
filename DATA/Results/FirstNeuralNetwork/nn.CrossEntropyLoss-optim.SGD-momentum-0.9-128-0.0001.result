batch_size: 128

learning_rate: 0.0001

model: BigCatClassifier(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu1): ReLU()
  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu2): ReLU()
  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc1): Linear(in_features=100352, out_features=256, bias=True)
  (relu3): ReLU()
  (dropout): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=256, out_features=10, bias=True)
) 

begin training

epoch,loss,test accuracy,valid accuracy
1,2.3100,10.0,10.0
2,2.2881,10.0,10.0
3,2.2964,10.0,10.0
4,2.3016,10.0,16.0
5,2.3100,10.0,20.0
6,2.2935,12.0,20.0
7,2.3022,10.0,18.0
8,2.2856,10.0,20.0
9,2.2867,12.0,18.0
10,2.2893,14.0,24.0
11,2.2889,12.0,22.0
12,2.2904,20.0,16.0
13,2.2864,14.0,24.0
14,2.2757,12.0,24.0
15,2.2816,12.0,24.0
16,2.2767,12.0,22.0
17,2.3004,14.0,22.0
18,2.2706,16.0,24.0
19,2.2584,24.0,22.0
20,2.2813,24.0,26.0
21,2.2644,24.0,20.0
22,2.2670,20.0,24.0
23,2.2672,14.0,26.0
24,2.2830,16.0,24.0
25,2.2824,20.0,22.0
26,2.2714,18.0,26.0
27,2.2507,22.0,24.0
28,2.2636,22.0,24.0
29,2.2622,20.0,24.0
30,2.2779,16.0,26.0
31,2.2663,22.0,30.0
32,2.2724,24.0,26.0
33,2.2479,20.0,24.0
34,2.2740,12.0,26.0
35,2.2413,16.0,28.0
36,2.2530,20.0,26.0
37,2.2461,22.0,30.0
38,2.2793,20.0,26.0
39,2.2503,26.0,26.0
40,2.2511,26.0,30.0
41,2.2419,20.0,28.0
42,2.2623,16.0,26.0
43,2.2369,22.0,26.0
44,2.2585,24.0,28.0
45,2.2412,24.0,28.0
46,2.2753,24.0,28.0
47,2.2030,20.0,26.0
48,2.2402,20.0,26.0
49,2.2439,20.0,30.0
50,2.2444,20.0,26.0
51,2.1936,22.0,26.0
52,2.2664,22.0,28.0
53,2.2016,20.0,26.0
54,2.2045,20.0,26.0
55,2.2242,26.0,24.0
56,2.1713,22.0,24.0
57,2.2132,20.0,24.0
58,2.2295,20.0,26.0
59,2.1653,18.0,24.0
60,2.2418,22.0,24.0
61,2.1294,24.0,28.0
62,2.1679,24.0,28.0
63,2.2253,24.0,24.0
64,2.1709,20.0,24.0
65,2.1895,18.0,26.0
66,2.1849,22.0,26.0
67,2.1161,22.0,24.0
68,2.2209,26.0,24.0
69,2.2095,20.0,24.0
70,2.2058,24.0,28.0
71,2.1499,20.0,26.0
72,2.1050,22.0,28.0
73,2.1451,26.0,26.0
74,2.1464,20.0,28.0
75,2.2320,22.0,26.0
76,2.1149,24.0,28.0
77,2.1502,22.0,28.0
78,2.1575,24.0,26.0
79,2.1233,24.0,28.0
80,2.1328,24.0,26.0
81,2.1603,24.0,30.0
82,2.1223,28.0,26.0
83,2.0882,24.0,28.0
84,2.0662,26.0,26.0
85,2.0402,26.0,24.0
86,2.2058,24.0,30.0
87,2.1909,28.0,32.0
88,2.0948,26.0,30.0
89,2.1042,26.0,28.0
90,2.0774,24.0,32.0
91,2.0062,28.0,32.0
92,2.0790,28.0,34.0
93,2.1398,22.0,30.0
94,2.1358,26.0,34.0
95,2.0126,28.0,32.0
96,2.1300,28.0,28.0
97,2.1337,26.0,32.0
98,1.9828,28.0,28.0
99,2.0678,26.0,30.0
100,2.0451,26.0,34.0
