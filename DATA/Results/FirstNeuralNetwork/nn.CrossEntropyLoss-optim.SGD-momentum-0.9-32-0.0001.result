batch_size: 32

learning_rate: 0.0001

model: BigCatClassifier(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu1): ReLU()
  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu2): ReLU()
  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc1): Linear(in_features=100352, out_features=256, bias=True)
  (relu3): ReLU()
  (dropout): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=256, out_features=10, bias=True)
) 

begin training

epoch,loss,test accuracy,valid accuracy
1,2.3361,16.0,18.0
2,2.2864,12.0,16.0
3,2.3105,12.0,16.0
4,2.3036,14.0,22.0
5,2.2456,16.0,22.0
6,2.4161,18.0,22.0
7,2.2955,20.0,28.0
8,2.3396,18.0,30.0
9,2.2506,22.0,26.0
10,2.2390,20.0,22.0
11,2.1612,22.0,28.0
12,2.1927,20.0,26.0
13,2.2497,20.0,22.0
14,2.2210,18.0,22.0
15,2.3131,22.0,22.0
16,2.2041,24.0,20.0
17,2.4980,20.0,20.0
18,2.1144,16.0,18.0
19,1.8290,22.0,22.0
20,2.0420,20.0,22.0
21,2.4078,22.0,24.0
22,1.9868,18.0,26.0
23,2.1157,24.0,26.0
24,2.3211,20.0,22.0
25,2.0513,24.0,24.0
26,2.5095,22.0,22.0
27,2.3106,20.0,26.0
28,2.0778,22.0,22.0
29,2.2948,24.0,24.0
30,2.6173,18.0,24.0
31,2.3458,22.0,30.0
32,2.0433,30.0,30.0
33,1.9792,22.0,28.0
34,2.0108,22.0,26.0
35,1.4750,24.0,32.0
36,1.9501,20.0,32.0
37,2.0237,26.0,28.0
38,1.6987,22.0,28.0
39,2.2331,24.0,34.0
40,1.4095,24.0,32.0
41,1.9903,30.0,30.0
42,2.3585,18.0,32.0
43,1.9673,34.0,38.0
44,1.6012,24.0,34.0
45,1.3894,24.0,40.0
46,0.7768,20.0,40.0
47,2.4430,22.0,36.0
48,1.1603,24.0,38.0
49,1.6842,38.0,36.0
50,2.5155,24.0,36.0
51,1.9422,28.0,38.0
52,2.2832,34.0,42.0
53,2.4475,28.0,42.0
54,0.7535,36.0,40.0
55,1.7132,30.0,42.0
56,1.9526,24.0,36.0
57,1.7402,32.0,38.0
58,2.2681,28.0,46.0
59,1.6302,30.0,40.0
60,1.3568,20.0,46.0
61,1.3379,26.0,38.0
62,1.5600,32.0,36.0
63,1.0407,32.0,42.0
64,0.9751,32.0,44.0
65,2.0078,32.0,44.0
66,1.7604,34.0,42.0
67,2.9183,26.0,48.0
68,1.3153,24.0,44.0
69,1.5549,30.0,46.0
70,1.8400,34.0,48.0
71,1.6243,30.0,44.0
72,2.5268,26.0,46.0
73,1.6093,32.0,46.0
74,1.7534,32.0,52.0
75,1.9749,26.0,42.0
76,1.2725,40.0,42.0
77,1.8536,34.0,46.0
78,0.7678,42.0,46.0
79,1.7213,36.0,44.0
80,2.1647,40.0,44.0
81,2.2328,28.0,42.0
82,1.0743,34.0,42.0
83,1.1643,38.0,42.0
84,1.6917,36.0,48.0
85,1.7674,42.0,54.0
86,0.7992,36.0,52.0
87,1.1289,42.0,44.0
88,1.5749,48.0,42.0
89,0.7320,42.0,50.0
90,1.4076,50.0,42.0
91,1.0340,38.0,48.0
92,0.9125,42.0,48.0
93,1.7361,42.0,48.0
94,2.3448,36.0,40.0
95,0.6840,48.0,44.0
96,1.1487,36.0,44.0
97,1.2356,44.0,46.0
98,1.8089,40.0,44.0
99,1.3869,42.0,48.0
100,1.8400,40.0,52.0
