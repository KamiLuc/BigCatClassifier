batch_size: 32

learning_rate: 0.001

model: BigCatClassifier2(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu1): ReLU()
  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu2): ReLU()
  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu3): ReLU()
  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc1): Linear(in_features=50176, out_features=256, bias=True)
  (relu4): ReLU()
  (dropout): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=256, out_features=10, bias=True)
) 

begin training

epoch,loss,test accuracy,valid accuracy
1,2.2920,12.0,12.0
2,2.1510,10.0,10.0
3,2.5184,16.0,28.0
4,0.7114,28.0,34.0
5,3.2875,34.0,42.0
6,0.9492,32.0,44.0
7,1.1370,54.0,52.0
8,0.7822,60.0,54.0
9,1.0532,60.0,54.0
10,1.8642,54.0,58.0
11,2.0946,58.0,58.0
12,1.6389,64.0,52.0
13,1.1593,58.0,58.0
14,0.9838,66.0,58.0
15,0.9273,66.0,54.0
16,0.6117,52.0,56.0
17,1.0458,62.0,52.0
18,1.3358,62.0,54.0
19,3.1728,50.0,48.0
20,0.6177,70.0,54.0
21,0.9672,62.0,54.0
22,0.5187,68.0,58.0
23,0.3924,68.0,60.0
24,1.0406,72.0,54.0
25,1.3562,70.0,56.0
26,0.7638,62.0,58.0
27,0.2879,74.0,56.0
28,0.5042,72.0,58.0
29,0.4995,72.0,58.0
30,0.4288,68.0,56.0
31,0.9479,64.0,56.0
32,0.0389,68.0,58.0
33,0.9264,78.0,66.0
34,0.7137,70.0,66.0
35,1.6723,70.0,64.0
36,0.2644,78.0,66.0
37,0.0763,74.0,62.0
38,0.7669,68.0,54.0
39,0.7155,72.0,62.0
40,0.1351,84.0,68.0
41,0.5751,72.0,64.0
42,0.7395,78.0,68.0
43,0.5548,72.0,58.0
44,1.6633,74.0,70.0
45,0.1824,74.0,68.0
46,0.0198,78.0,70.0
47,0.3747,82.0,66.0
48,0.8117,78.0,70.0
49,0.2970,76.0,66.0
50,2.8139,72.0,68.0
51,0.9998,72.0,58.0
52,0.4026,78.0,70.0
53,0.0953,74.0,72.0
54,0.7977,72.0,72.0
55,0.3275,82.0,72.0
56,1.0099,76.0,68.0
57,0.3914,78.0,72.0
58,0.2851,76.0,58.0
59,0.4816,76.0,72.0
60,0.3983,78.0,72.0
61,0.2772,82.0,70.0
62,0.4375,78.0,66.0
63,0.0199,78.0,72.0
64,0.6071,86.0,62.0
65,0.0101,84.0,70.0
66,0.0260,84.0,72.0
67,0.1515,88.0,72.0
68,0.0311,80.0,68.0
69,0.0012,78.0,70.0
70,0.0099,72.0,60.0
71,0.3174,80.0,68.0
72,0.0463,82.0,64.0
73,0.1710,78.0,72.0
74,0.1428,78.0,68.0
75,0.1078,80.0,70.0
76,0.0271,86.0,70.0
77,1.1739,82.0,66.0
78,0.0648,80.0,72.0
79,0.7007,78.0,66.0
80,0.2214,80.0,64.0
81,0.3800,80.0,64.0
82,0.2206,80.0,64.0
83,0.2054,82.0,58.0
84,0.0117,80.0,64.0
85,0.0028,84.0,66.0
86,0.3358,82.0,64.0
87,0.2500,78.0,64.0
88,2.2550,78.0,68.0
89,1.1424,82.0,64.0
90,0.2668,82.0,68.0
91,0.0004,76.0,64.0
92,0.0434,78.0,72.0
93,0.0046,82.0,68.0
94,0.0037,78.0,68.0
95,0.0156,82.0,68.0
96,0.2154,90.0,62.0
97,0.0030,82.0,64.0
98,0.0311,86.0,62.0
99,0.0001,82.0,60.0
100,0.0500,86.0,68.0
101,0.0060,80.0,66.0
102,0.0507,80.0,68.0
103,0.1048,84.0,68.0
104,0.0792,86.0,64.0
105,0.0023,78.0,68.0
106,0.0718,84.0,60.0
107,0.0010,78.0,66.0
108,0.0058,84.0,66.0
109,0.0804,84.0,66.0
110,0.0711,86.0,64.0
111,0.0001,82.0,64.0
112,0.1437,82.0,66.0
113,0.0005,86.0,64.0
114,0.0875,84.0,68.0
115,0.0155,74.0,64.0
116,0.7158,86.0,72.0
117,0.0007,84.0,62.0
118,0.0012,78.0,62.0
119,0.0333,80.0,66.0
120,0.7089,86.0,64.0
121,0.2003,88.0,68.0
122,0.4565,84.0,64.0
123,0.0712,82.0,68.0
124,0.0016,78.0,64.0
125,0.0485,88.0,64.0
126,0.0298,84.0,66.0
127,0.2325,76.0,62.0
128,0.1327,90.0,64.0
129,0.0135,90.0,64.0
130,0.0848,82.0,70.0
131,0.0040,84.0,66.0
132,0.0004,88.0,68.0
133,0.0003,84.0,68.0
134,0.0794,90.0,72.0
135,0.0794,86.0,62.0
136,0.5924,84.0,68.0
137,0.0029,84.0,64.0
138,0.0001,86.0,64.0
139,0.0427,86.0,64.0
140,0.0966,86.0,62.0
141,0.0009,88.0,62.0
142,0.2515,86.0,68.0
143,0.0238,86.0,68.0
144,0.0002,80.0,62.0
145,0.0003,86.0,64.0
146,0.1783,88.0,70.0
147,0.2615,80.0,70.0
148,0.3349,84.0,66.0
149,0.1989,78.0,70.0
150,0.4886,86.0,68.0
