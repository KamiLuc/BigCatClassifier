batch_size: 32

learning_rate: 0.0001

model: BigCatClassifier2(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu1): ReLU()
  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu2): ReLU()
  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu3): ReLU()
  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc1): Linear(in_features=50176, out_features=256, bias=True)
  (relu4): ReLU()
  (dropout): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=256, out_features=10, bias=True)
) 

begin training

epoch,loss,test accuracy,valid accuracy
1,2.3049,10.0,10.0
2,2.3072,10.0,10.0
3,2.2836,10.0,10.0
4,2.2800,10.0,10.0
5,2.2986,10.0,10.0
6,2.2964,8.0,10.0
7,2.2580,6.0,10.0
8,2.3297,12.0,10.0
9,2.3132,12.0,10.0
10,2.2831,12.0,10.0
11,2.2557,12.0,10.0
12,2.2722,12.0,10.0
13,2.2952,12.0,10.0
14,2.2830,12.0,10.0
15,2.2455,14.0,12.0
16,2.3328,14.0,10.0
17,2.2847,14.0,12.0
18,2.2661,10.0,12.0
19,2.2790,10.0,14.0
20,2.3158,10.0,20.0
21,2.2710,10.0,20.0
22,2.2398,12.0,18.0
23,2.2905,10.0,18.0
24,2.2888,12.0,22.0
25,2.2466,12.0,18.0
26,2.2662,12.0,22.0
27,2.2990,10.0,24.0
28,2.2830,10.0,20.0
29,2.2752,10.0,22.0
30,2.3169,12.0,20.0
31,2.2534,12.0,20.0
32,2.2601,10.0,20.0
33,2.2771,12.0,20.0
34,2.3219,10.0,22.0
35,2.3303,10.0,22.0
36,2.3059,10.0,20.0
37,2.2961,12.0,20.0
38,2.3531,10.0,20.0
39,2.1875,10.0,20.0
40,2.3229,14.0,20.0
41,2.3430,12.0,18.0
42,2.2677,10.0,18.0
43,2.2708,10.0,18.0
44,2.2146,10.0,20.0
45,2.3072,10.0,20.0
46,2.2180,14.0,22.0
47,2.2321,10.0,20.0
48,2.2159,12.0,20.0
49,2.2886,12.0,20.0
50,2.2874,10.0,22.0
51,2.1869,16.0,22.0
52,2.2297,16.0,22.0
53,2.3077,18.0,22.0
54,2.3088,16.0,22.0
55,2.3178,16.0,24.0
56,2.1228,16.0,24.0
57,2.0925,16.0,24.0
58,2.1007,18.0,26.0
59,2.0443,14.0,22.0
60,2.2778,16.0,22.0
61,2.2567,18.0,24.0
62,2.1206,16.0,20.0
63,1.9804,18.0,16.0
64,2.0355,18.0,24.0
65,2.4886,24.0,18.0
66,2.0255,24.0,18.0
67,1.8179,20.0,20.0
68,1.9799,18.0,22.0
69,2.5473,16.0,22.0
70,2.2345,22.0,18.0
71,2.0694,22.0,20.0
72,2.1199,26.0,24.0
73,1.8978,24.0,20.0
74,1.9785,30.0,20.0
75,2.2038,20.0,18.0
76,2.3965,22.0,28.0
77,1.6526,22.0,26.0
78,2.1951,26.0,22.0
79,2.0819,32.0,22.0
80,1.8023,22.0,20.0
81,1.2936,28.0,32.0
82,2.0809,22.0,22.0
83,1.7135,24.0,34.0
84,2.1213,20.0,30.0
85,2.7952,18.0,26.0
86,1.3727,26.0,36.0
87,1.5178,20.0,34.0
88,1.9230,20.0,32.0
89,1.8450,18.0,32.0
90,1.4587,28.0,34.0
91,1.8943,22.0,38.0
92,1.7323,24.0,38.0
93,2.1669,22.0,40.0
94,1.8345,22.0,38.0
95,2.0564,24.0,38.0
96,1.3207,22.0,40.0
97,1.3259,24.0,36.0
98,1.8411,32.0,32.0
99,1.8190,24.0,36.0
100,1.2937,20.0,42.0
