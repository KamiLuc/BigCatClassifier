batch_size: 256

learning_rate: 0.001

model: BigCatClassifier2(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu1): ReLU()
  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu2): ReLU()
  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu3): ReLU()
  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc1): Linear(in_features=50176, out_features=256, bias=True)
  (relu4): ReLU()
  (dropout): Dropout(p=0.5, inplace=False)
  (fc2): Linear(in_features=256, out_features=10, bias=True)
) 

begin training

epoch,loss,test accuracy,valid accuracy
1,2.2874,12.0,10.0
2,2.1469,20.0,30.0
3,1.8094,34.0,44.0
4,1.8345,32.0,38.0
5,1.5907,16.0,32.0
6,1.6988,32.0,36.0
7,1.9581,34.0,40.0
8,1.3361,42.0,44.0
9,1.4086,30.0,38.0
10,1.5001,36.0,44.0
11,1.3645,44.0,42.0
12,1.4348,54.0,44.0
13,1.1980,66.0,46.0
14,1.4502,58.0,50.0
15,1.2059,62.0,56.0
16,1.1105,54.0,52.0
17,1.2560,58.0,48.0
18,1.1334,60.0,50.0
19,1.0932,60.0,56.0
20,0.8857,64.0,56.0
21,0.9679,62.0,60.0
22,0.9131,60.0,54.0
23,0.9461,64.0,62.0
24,0.9713,58.0,54.0
25,1.2730,54.0,52.0
26,0.9623,66.0,62.0
27,1.3812,64.0,64.0
28,1.1793,66.0,64.0
29,0.7234,62.0,62.0
30,0.9092,68.0,62.0
31,0.6096,70.0,64.0
32,0.6985,66.0,68.0
33,0.4311,72.0,66.0
34,0.5258,68.0,66.0
35,0.8054,66.0,62.0
36,0.6039,68.0,58.0
37,0.3894,66.0,64.0
38,0.9285,68.0,66.0
39,0.5226,74.0,70.0
40,0.8282,72.0,62.0
41,0.4233,74.0,64.0
42,0.5948,74.0,66.0
43,0.4552,74.0,66.0
44,0.5805,76.0,64.0
45,0.5411,74.0,66.0
46,0.5053,74.0,64.0
47,0.4969,70.0,64.0
48,0.5621,76.0,66.0
49,0.3151,74.0,66.0
50,0.2962,78.0,68.0
51,0.2660,76.0,66.0
52,0.3632,76.0,64.0
53,0.4063,74.0,68.0
54,0.5482,74.0,66.0
55,0.2879,66.0,62.0
56,0.3721,76.0,70.0
57,0.3097,74.0,66.0
58,0.2778,80.0,70.0
59,0.3638,74.0,66.0
60,0.1904,74.0,66.0
61,0.6719,74.0,62.0
62,0.3675,76.0,68.0
63,0.2222,74.0,66.0
64,0.2567,70.0,66.0
65,0.4482,74.0,68.0
66,0.3052,76.0,66.0
67,0.0789,80.0,68.0
68,0.4718,76.0,72.0
69,0.2287,80.0,68.0
70,0.2509,74.0,68.0
71,0.4502,74.0,68.0
72,0.3486,78.0,68.0
73,0.2597,74.0,62.0
74,0.2413,76.0,68.0
75,0.0978,74.0,70.0
76,0.1680,74.0,70.0
77,0.2427,78.0,68.0
78,0.2004,80.0,70.0
79,0.2442,76.0,64.0
80,0.1129,76.0,70.0
81,0.1636,78.0,68.0
82,0.2040,78.0,68.0
83,0.2166,78.0,66.0
84,0.1240,74.0,66.0
85,0.2284,70.0,68.0
86,0.1960,76.0,68.0
87,0.2788,74.0,66.0
88,0.2209,70.0,66.0
89,0.1699,80.0,68.0
90,0.0864,78.0,66.0
91,0.0702,80.0,70.0
92,0.1164,76.0,68.0
93,0.2524,78.0,66.0
94,0.0869,72.0,66.0
95,0.1125,76.0,68.0
96,0.0486,76.0,70.0
97,0.1038,76.0,70.0
98,0.1208,76.0,70.0
99,0.2504,80.0,68.0
100,0.1182,74.0,68.0
101,0.2251,80.0,72.0
102,0.1639,78.0,66.0
103,0.1639,80.0,66.0
104,0.1158,78.0,64.0
105,0.1949,74.0,66.0
106,0.0286,74.0,66.0
107,0.0437,76.0,68.0
108,0.1025,76.0,68.0
109,0.0190,76.0,70.0
110,0.0820,80.0,64.0
111,0.1320,78.0,64.0
112,0.1180,76.0,70.0
113,0.0243,76.0,66.0
114,0.1059,74.0,60.0
115,0.0771,70.0,70.0
116,0.0982,70.0,68.0
117,0.0835,72.0,70.0
118,0.3141,82.0,70.0
119,0.1590,74.0,70.0
120,0.1484,78.0,68.0
121,0.0603,76.0,66.0
122,0.0973,80.0,66.0
123,0.2189,76.0,68.0
124,0.2932,72.0,70.0
125,0.1471,80.0,66.0
126,0.0700,80.0,68.0
127,0.3383,76.0,62.0
128,0.0269,82.0,66.0
129,0.1977,80.0,66.0
130,0.1594,76.0,70.0
131,0.0704,78.0,64.0
132,0.0912,78.0,72.0
133,0.2173,74.0,70.0
134,0.0637,78.0,68.0
135,0.2130,72.0,70.0
136,0.0759,76.0,70.0
137,0.0358,72.0,66.0
138,0.0511,74.0,74.0
139,0.0286,74.0,72.0
140,0.1800,74.0,68.0
141,0.0669,76.0,68.0
142,0.0107,76.0,64.0
143,0.0206,76.0,70.0
144,0.0297,80.0,72.0
145,0.0288,72.0,74.0
146,0.0243,78.0,70.0
147,0.1881,78.0,72.0
148,0.0856,80.0,68.0
149,0.0400,80.0,68.0
150,0.0541,72.0,66.0
